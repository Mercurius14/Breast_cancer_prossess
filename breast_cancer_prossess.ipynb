{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_path = './images/'\n",
    "mask_path = './masks/'\n",
    "thumbnails_path = './thumbnails/'\n",
    "transform_path=  './mask_transform/'\n",
    "save_img_path = './init_data_image/'\n",
    "save_init_path = './init_data/'\n",
    "compress_path =  './compress/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取'image'文件夹里面的图片和'mask'文件夹里面的图片，将其对应的图片一起切片成224*224的图片，保存在'thumbnails'文件夹里面\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 定义图片的尺寸和切片大小\n",
    "image_size = (224, 224)\n",
    "slice_size = 224\n",
    "\n",
    "# 创建保存切片的文件夹\n",
    "os.makedirs('./thumbnails/images', exist_ok=True)\n",
    "os.makedirs('./thumbnails/masks', exist_ok=True)\n",
    "\n",
    "# 读取'image'文件夹和'mask'文件夹中的图片\n",
    "image_files = sorted(os.listdir('./images'))\n",
    "mask_files = sorted(os.listdir('./masks'))\n",
    "\n",
    "# 确保'image'文件夹和'mask'文件夹中图片数量相同\n",
    "if len(image_files) != len(mask_files):\n",
    "    print(\"Error: The number of images in 'image' folder is different from the number of images in 'mask' folder.\")\n",
    "    exit()\n",
    "\n",
    "# 逐个处理每张图片\n",
    "for i, (image_file, mask_file) in enumerate(zip(image_files, mask_files)):\n",
    "    # 打开图片和对应的mask\n",
    "    image_path = os.path.join('./images', image_file)\n",
    "    mask_path = os.path.join('./masks', mask_file)\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    # 确保图片和mask的尺寸相同\n",
    "    if image.size != mask.size:\n",
    "        print(f\"Error: Image size doesn't match mask size for image {image_file}. Skipping this image.\")\n",
    "        continue\n",
    "\n",
    "    # 计算切片的行数和列数\n",
    "    rows = image.size[1] // slice_size\n",
    "    cols = image.size[0] // slice_size\n",
    "\n",
    "    # 逐个切片并保存\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 计算切片的区域\n",
    "            left = col * slice_size\n",
    "            upper = row * slice_size\n",
    "            right = left + slice_size\n",
    "            lower = upper + slice_size\n",
    "\n",
    "            # 裁剪图片和对应的mask\n",
    "            image_slice = image.crop((left, upper, right, lower))\n",
    "            mask_slice = mask.crop((left, upper, right, lower))\n",
    "\n",
    "            # 保存切片图片和对应的mask\n",
    "            slice_name = f'x_{row}_y_{col}_{i}.png'\n",
    "            image_slice.save(os.path.join('thumbnails/images', slice_name))\n",
    "            mask_slice.save(os.path.join('thumbnails/masks', slice_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48811/48811 [10:22<00:00, 78.40it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 创建保存切片的文件夹\n",
    "os.makedirs('./init_data_image/images', exist_ok=True)\n",
    "os.makedirs('./init_data_image/masks', exist_ok=True)\n",
    "# 读取'image'文件夹和'mask'文件夹中的图片\n",
    "images_files = sorted(os.listdir('./thumbnails/images'))\n",
    "masks_files = sorted(os.listdir('./thumbnails/masks'))\n",
    "# 将第前27张图片里面的切片提出来保存在 init_images文件夹里面\n",
    "# 生成1到27的数组\n",
    "num = np.arange(1,28)\n",
    "for i in tqdm(range(len(images_files))):\n",
    "    file_id = images_files[i].split('_')[4].split('.')[0]\n",
    "    if int(file_id) in num:\n",
    "        image_path = os.path.join('./thumbnails/images', images_files[i])\n",
    "        mask_path = os.path.join('./thumbnails/masks', masks_files[i])\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        image_file_change = file_id+'_x_'+images_files[i].split('_')[1]+\"_y_\"+images_files[i].split('_')[3]+\".png\"\n",
    "        image.save(os.path.join('./init_data_image/images', image_file_change))\n",
    "        mask.save(os.path.join('./init_data_image/masks', image_file_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看masks二值图像\n",
    "# 读取./init_data_image/masks文件夹里面的第一张图片，打印出来，平切查看numpy格式\n",
    "mask = Image.open('./masks/TCGA-A1-A0SK-DX1_xmin45749_ymin25055_MPP-0.2500.png')\n",
    "# 将像素值为1的转成红色，其他的转成绿色，将这个改成RGB格式的图片\n",
    "mask = mask.convert('RGB')\n",
    "mask_arr = np.array(mask)\n",
    "# 将像素值不为1的转成0\n",
    "mask_arr[mask_arr!=1]=0\n",
    "# 将mask_arr里面的像素值为1的转成红色，其他的转成绿色\n",
    "colors=[\n",
    "    [137,212,94], # 绿色\n",
    "    [210,36,36], # 红色\n",
    "    [240,65,69], # \n",
    "]\n",
    "for i in range(mask_arr.shape[0]):\n",
    "    for j in range(mask_arr.shape[1]):\n",
    "        mask_arr[i,j,:]=colors[mask_arr[i,j,0]] # 将mask_arr里面的像素值为1的转成红色，其他的转成绿色\n",
    "mask = Image.fromarray(mask_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mask(mask,filename,mask_file):\n",
    "    mask = mask.convert('RGB')\n",
    "    mask_arr = np.array(mask)\n",
    "    # 将像素值不为1的转成0\n",
    "    mask_arr[mask_arr!=1]=0\n",
    "    # 将mask_arr里面的像素值为1的转成红色，其他的转成绿色\n",
    "    colors=[\n",
    "        [137,212,94],\n",
    "        [210,36,36],\n",
    "        [240,65,69],\n",
    "    ]\n",
    "    for i in range(mask_arr.shape[0]):\n",
    "        for j in range(mask_arr.shape[1]):\n",
    "            mask_arr[i,j,:]=colors[mask_arr[i,j,0]]\n",
    "    mask = Image.fromarray(mask_arr)\n",
    "    path= f'./mask_transform/{filename}'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    mask.save(path+f'/{mask_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对图像进行癌症标签的分类\n",
    "\n",
    "# 定义路径和标签字典\n",
    "images_dir = './init_data_image/images'\n",
    "masks_dir = './init_data_image/masks'\n",
    "init_images_dir = './init_images'\n",
    "labels_dict = {0: '0',1: '1', 2: '2', 3: '3'}\n",
    "\n",
    "masks_files = sorted(os.listdir(masks_dir))\n",
    "images_files = sorted(os.listdir(images_dir))\n",
    "\n",
    "# 定义函数来计算面积比和获取标签\n",
    "def get_label(mask):\n",
    "    # 计算像素值为1的个数\n",
    "\n",
    "    cancer_act_rate = [0.05, 0.15, 0.65, 0.9]\n",
    "    interval=0.05\n",
    "\n",
    "    num_1 = np.sum(mask == 1)\n",
    "    area_ratio = num_1 / (224*224)\n",
    "    if area_ratio > cancer_act_rate[0] and area_ratio < cancer_act_rate[1]:\n",
    "        label = 1  # no cancer\n",
    "    elif area_ratio > cancer_act_rate[1]+interval and area_ratio < cancer_act_rate[2]:\n",
    "        label = 2  # cancer\n",
    "    elif area_ratio > cancer_act_rate[2]+interval and area_ratio < cancer_act_rate[3]:\n",
    "        label = 3  # more cancer\n",
    "    else :\n",
    "        label = 0 # 无效label\n",
    "    return label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7925/7925 [05:04<00:00, 26.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无癌症数量： 348 \n",
      " 癌症数量： 1551 \n",
      " 重度癌症数量： 699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有切片图像\n",
    "label1 = []\n",
    "label2 = []\n",
    "label3 = []\n",
    "label0 = []\n",
    "masks_dir = './init_data_image/masks'\n",
    "images_dir = './init_data_image/images'\n",
    "images_files=sorted(os.listdir(images_dir))\n",
    "masks_files = sorted(os.listdir(masks_dir))\n",
    "num_id = 1\n",
    "middle_value = 0\n",
    "for filename in tqdm(images_files):\n",
    "    \n",
    "    if filename.endswith('.png'):\n",
    "        # 解析图像的行、列、切片编号\n",
    "        filename_parts = filename.split('_')\n",
    "        i, j, k = int(filename_parts[2]), int(filename_parts[4].split('.')[0]), int(filename_parts[0])\n",
    "        \n",
    "        if middle_value == k:\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(f'./init_images/image_{k}', exist_ok=True)\n",
    "            filename_path = f'./init_images/image_{k}'\n",
    "            middle_value = k\n",
    "            num_id = 1\n",
    "        # 读取切片图像和对应的masks图像\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "        image = np.array(Image.open(image_path))\n",
    "        mask_path = os.path.join(masks_dir, filename)\n",
    "        mask = np.array(Image.open(mask_path))\n",
    "        # transform_mask(Image.open(mask_path),f'image{k}',filename)\n",
    "        # 计算标签\n",
    "        label = get_label(mask)\n",
    "        if label == 1:\n",
    "            label1.append(filename)\n",
    "        elif label == 2:\n",
    "            label2.append(filename)\n",
    "        elif label == 3:\n",
    "            label3.append(filename)\n",
    "        else:\n",
    "            label0.append(filename)\n",
    "        # 保存图像和标签\n",
    "        new_filename = f'{k}_{num_id}_{labels_dict[label]}.png'\n",
    "        new_image_path = os.path.join(filename_path, new_filename)\n",
    "        Image.fromarray(image).save(new_image_path)\n",
    "        num_id+=1\n",
    "# 打印label1、label2、label3的长度\n",
    "print('无癌症数量：',len(label1),'\\n 癌症数量：', len(label2),'\\n 重度癌症数量：', len(label3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def npy_data_init_percent(\n",
    "        img_path,  # /init_data_image\n",
    "        save_path,  # /init_data\n",
    "        label_rate=0.5,\n",
    "        test_rate=0.2,\n",
    "        size=224,\n",
    "        img_num=0,\n",
    "):\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # imglen是wsi图的个数\n",
    "    train_dataset = []\n",
    "    labeled_set = []\n",
    "    unlabeled_set = []\n",
    "    test_dataset = []\n",
    "    files = []\n",
    "    ts_files=[]\n",
    "\n",
    "\n",
    "    transformations = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "    )\n",
    "\n",
    "    global_index = 0\n",
    "    for imgid in tqdm(range(img_num)):\n",
    "        files_path = []\n",
    "        path = os.path.join(img_path, 'image_'+str(imgid+1))\n",
    "\n",
    "        for file_name in os.listdir(path):\n",
    "            lb=int(file_name.split('_')[-1][0]) \n",
    "            if lb!=0:\n",
    "                files_path.append(file_name)\n",
    "\n",
    "        patch_num = len(files_path)\n",
    "        #\n",
    "        rand_init = torch.randperm(patch_num)\n",
    "        labeled_index = rand_init[:int(label_rate*patch_num)]\n",
    "        unlabeled_index = rand_init[int(\n",
    "            label_rate*patch_num): int((1-test_rate)*patch_num)]\n",
    "        \n",
    "        \n",
    "        # labeled and unlabeled\n",
    "        for patch_index in rand_init[:int((1-test_rate)*patch_num)]:\n",
    "            files.append((imgid, patch_index, files_path[patch_index]))\n",
    "            image = Image.open(os.path.join(path, files_path[patch_index]))\n",
    "            new_data = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "            img = transformations(new_data)\n",
    "            label = int(files_path[patch_index][-5])\n",
    "            train_dataset.append(\n",
    "                (img, label, patch_index, imgid, global_index))\n",
    "            if patch_index in labeled_index:\n",
    "                labeled_set.append(\n",
    "                    (img, label, patch_index, imgid, global_index))\n",
    "\n",
    "            elif patch_index in unlabeled_index:\n",
    "                unlabeled_set.append(\n",
    "                    (img, label, patch_index, imgid, global_index))\n",
    "\n",
    "            global_index += 1\n",
    "        \n",
    "        \n",
    "        # test\n",
    "        for patch_index in rand_init[int((1-test_rate)*patch_num):]:\n",
    "            ts_files.append((imgid, patch_index, files_path[patch_index]))\n",
    "            image = Image.open(os.path.join(path, files_path[patch_index]))\n",
    "            new_data = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "            img = transformations(new_data)\n",
    "            label = int(files_path[patch_index][-5])\n",
    "            test_dataset.append((img, label, patch_index, imgid, 0))\n",
    "\n",
    "    train_dataset = np.array(train_dataset)\n",
    "    labeled_set = np.array(labeled_set)\n",
    "    unlabeled_set = np.array(unlabeled_set)\n",
    "    test_dataset = np.array(test_dataset)\n",
    "    \n",
    "    print(len(train_dataset), len(labeled_set), len(\n",
    "        unlabeled_set), len(test_dataset), len(files))\n",
    "\n",
    "    #\n",
    "    np.save(os.path.join(save_path, \"patch_file.npy\"), np.array(files))\n",
    "    np.save(os.path.join(save_path, \"ts_patch_file.npy\"), np.array(ts_files))\n",
    "\n",
    "    np.save(os.path.join(save_path, \"train_dataset.npy\"), train_dataset)\n",
    "    np.save(os.path.join(save_path, \"init_labeled_set.npy\"), labeled_set)\n",
    "    np.save(os.path.join(save_path, \"init_unlabeled_set.npy\"), unlabeled_set)\n",
    "    np.save(os.path.join(save_path, \"test_dataset.npy\"), test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img_path = './init_data/'\n",
    "img_path = './init_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [02:55<00:00,  9.77s/it]\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:73: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_dataset = np.array(train_dataset)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:73: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_dataset = np.array(train_dataset)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:74: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  labeled_set = np.array(labeled_set)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  labeled_set = np.array(labeled_set)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:75: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  unlabeled_set = np.array(unlabeled_set)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:75: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  unlabeled_set = np.array(unlabeled_set)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:76: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  test_dataset = np.array(test_dataset)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/3498081373.py:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_dataset = np.array(test_dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336 2713 1623 1092 4336\n"
     ]
    }
   ],
   "source": [
    "npy_data_init_percent(img_path=img_path,save_path=save_img_path,img_num=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "好的，我来一行一行地讲解这段代码的作用：\n",
    "\n",
    "1. `def npy_data_init_percent(`：定义一个名为`npy_data_init_percent`的函数，用于初始化数据集。\n",
    "2. `img_path, save_path, label_rate=0.5, test_rate=0.2, size=224, img_num=0):`：定义函数的参数，包括图像路径、保存路径、有标签数据比例、测试数据比例、图像大小和图像数量。\n",
    "3. `if not os.path.exists(save_path):`：如果保存路径不存在，则创建该路径。\n",
    "4. `os.makedirs(save_path)`：创建保存路径。\n",
    "5. `train_dataset = []`：定义一个空列表，用于存储训练集的数据。\n",
    "6. `labeled_set = []`：定义一个空列表，用于存储有标签集的数据。\n",
    "7. `unlabeled_set = []`：定义一个空列表，用于存储无标签集的数据。\n",
    "8. `test_dataset = []`：定义一个空列表，用于存储测试集的数据。\n",
    "9. `files = []`：定义一个空列表，用于存储所有数据的文件名。\n",
    "10. `ts_files=[]`：定义一个空列表，用于存储测试集的文件名。\n",
    "11. `transformations = transforms.Compose([`：定义一个数据转换器，用于将图像数据转换为张量，并进行归一化处理。\n",
    "12. `transforms.Resize(size),`：将图像大小调整为指定大小。\n",
    "13. `transforms.ToTensor(),`：将图像数据转换为张量。\n",
    "14. `transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])`：对张量进行归一化处理。\n",
    "15. `global_index = 0`：定义一个全局索引，用于标记每个数据的唯一编号。\n",
    "16. `for imgid in tqdm(range(img_num)):`：遍历每个图像文件夹。\n",
    "17. `files_path = []`：定义一个空列表，用于存储当前图像文件夹中的所有文件名。\n",
    "18. `path = os.path.join(img_path, 'image_'+str(imgid))`：获取当前图像文件夹的路径。\n",
    "19. `for file_name in os.listdir(path):`：遍历当前图像文件夹中的所有文件。\n",
    "20. `lb=int(file_name.split('.')[0][-1])`：从文件名中获取标签。\n",
    "21. `if lb!=0:`：如果标签不为0，则将文件名添加到`files_path`列表中。\n",
    "22. `patch_num = len(files_path)`：获取当前图像文件夹中的文件数量。\n",
    "23. `rand_init = torch.randperm(patch_num)`：生成一个随机排列，用于随机选择有标签数据、无标签数据和测试数据。\n",
    "24. `labeled_index = rand_init[:int(label_rate*patch_num)]`：根据有标签数据比例，选择有标签数据的索引。\n",
    "25. `unlabeled_index = rand_init[int(label_rate*patch_num): int((1-test_rate)*patch_num)]`：根据有标签数据比例和测试数据比例，选择无标签数据的索引。\n",
    "26. `for patch_index in rand_init[:int((1-test_rate)*patch_num)]:`：遍历有标签数据和无标签数据。\n",
    "27. `files.append((imgid, patch_index, files_path[patch_index]))`：将当前数据的文件名、图像编号和索引添加到`files`列表中。\n",
    "28. `image = Image.open(os.path.join(path, files_path[patch_index]))`：打开当前数据的图像文件。\n",
    "29. `new_data = Image.fromarray(np.uint8(image)).convert('RGB')`：将图像数据转换为RGB格式。\n",
    "30. `img = transformations(new_data)`：将图像数据转换为张量，并进行归一化处理。\n",
    "31. `label = int(files_path[patch_index][-5])`：从文件名中获取当前数据的标签。\n",
    "32. `train_dataset.append((img, label, patch_index, imgid, global_index))`：将当前数据的图像数据、标签、索引、图像编号和唯一编号添加到训练集中。\n",
    "33. `if patch_index in labeled_index:`：如果当前数据的索引在有标签数据的索引中。\n",
    "34. `labeled_set.append((img, label, patch_index, imgid, global_index))`：将当前数据的图像数据、标签、索引、图像编号和唯一编号添加到有标签集中。\n",
    "35. `elif patch_index in unlabeled_index:`：如果当前数据的索引在无标签数据的索引中。\n",
    "36. `unlabeled_set.append((img, label, patch_index, imgid, global_index))`：将当前数据的图像数据、标签、索引、图像编号和唯一编号添加到无标签集中。\n",
    "37. `global_index += 1`：全局索引加1。\n",
    "38. `for patch_index in rand_init[int((1-test_rate)*patch_num):]:`：遍历测试数据。\n",
    "39. `ts_files.append((imgid, patch_index, files_path[patch_index]))`：将当前数据的文件名、图像编号和索引添加到测试集的文件名列表中。\n",
    "40. `image = Image.open(os.path.join(path, files_path[patch_index]))`：打开当前数据的图像文件。\n",
    "41. `new_data = Image.fromarray(np.uint8(image)).convert('RGB')`：将图像数据转换为RGB格式。\n",
    "42. `img = transformations(new_data)`：将图像数据转换为张量，并进行归一化处理。\n",
    "43. `label = int(files_path[patch_index][-5])`：从文件名中获取当前数据的标签。\n",
    "44. `test_dataset.append((img, label, patch_index, imgid, 0))`：将当前数据的图像数据、标签、索引、图像编号和0添加到测试集中。\n",
    "45. `train_dataset = np.array(train_dataset)`：将训练集转换为numpy数组。\n",
    "46. `labeled_set = np.array(labeled_set)`：将有标签集转换为numpy数组。\n",
    "47. `unlabeled_set = np.array(unlabeled_set)`：将无标签集转换为numpy数组。\n",
    "48. `test_dataset = np.array(test_dataset)`：将测试集转换为numpy数组。\n",
    "49. `print(len(train_dataset), len(labeled_set), len(unlabeled_set), len(test_dataset), len(files))`：打印数据集的大小信息。\n",
    "50. `np.save(os.path.join(save_path, \"patch_file.npy\"), np.array(files))`：将所有数据的文件名保存到指定路径中。\n",
    "51. `np.save(os.path.join(save_path, \"ts_patch_file.npy\"), np.array(ts_files))`：将测试集的文件名保存到指定路径中。\n",
    "52. `np.save(os.path.join(save_path, \"train_dataset.npy\"), train_dataset)`：将训练集保存到指定路径中。\n",
    "53. `np.save(os.path.join(save_path, \"init_labeled_set.npy\"), labeled_set)`：将有标签集保存到指定路径中。\n",
    "54. `np.save(os.path.join(save_path, \"init_unlabeled_set.npy\"), unlabeled_set)`：将无标签集保存到指定路径中。\n",
    "55. `np.save(os.path.join(save_path, \"test_dataset.npy\"), test_dataset)`：将测试集保存到指定路径中。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_data_init_bk(\n",
    "        img_path,  # /init_data_image\n",
    "        save_path,  # /init_data\n",
    "        size=224,\n",
    "        img_num=0,\n",
    "):\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # imglen是wsi图的个数\n",
    "    bk_files=[]\n",
    "    bk_data=[]\n",
    "\n",
    "    transformations = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "    global_index = 0\n",
    "    for imgid in tqdm(range(img_num)):\n",
    "        bk_files_path=[]\n",
    "        path = os.path.join(img_path, 'image_'+str(imgid+1))\n",
    "\n",
    "        for file_name in os.listdir(path):\n",
    "            lb=int(file_name.split('_')[-1][0]) \n",
    "            if lb==0:\n",
    "                bk_files_path.append(file_name)\n",
    "        #print(imgid,len(bk_files_path))\n",
    "        # bk\n",
    "        for patch_index in range(len(bk_files_path)):\n",
    "            bk_files.append((imgid, patch_index, bk_files_path[patch_index]))\n",
    "            image = Image.open(os.path.join(path, bk_files_path[patch_index]))\n",
    "            new_data = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "            img = transformations(new_data)\n",
    "            label = int(bk_files_path[patch_index][-5])\n",
    "            bk_data.append(\n",
    "                (img, label, patch_index, imgid, global_index))\n",
    "    \n",
    "    bk_data = np.array(bk_data)\n",
    "    bk_files = np.array(bk_files)\n",
    "\n",
    "    print(len(bk_data),len(bk_files))\n",
    "    np.save(os.path.join(save_path, \"bk_dataset.npy\"), bk_data)\n",
    "    np.save(os.path.join(save_path, \"bk_patch_file.npy\"), bk_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img_path = './init_data/'\n",
    "img_path = './init_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:35<00:00,  1.94s/it]\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/289861869.py:39: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  bk_data = np.array(bk_data)\n",
      "/var/folders/th/_3txp6g94497mdxt9g429v5r0000gn/T/ipykernel_2507/289861869.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bk_data = np.array(bk_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528 3528\n"
     ]
    }
   ],
   "source": [
    "npy_data_init_bk(\n",
    "        img_path=img_path,\n",
    "        save_path=save_img_path,\n",
    "        img_num=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
